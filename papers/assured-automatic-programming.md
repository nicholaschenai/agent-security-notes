---
date: 2025-02-26
time: 18:05
author: 
title: Assured Automatic Programming via Large Language Models
created-date: 2025-02-26
tags: 
paper: https://arxiv.org/abs/2410.18494
code: 
zks-type: lit
---

==draft mode via LM summary==


**General Summary:** The paper "Assured Automatic Programming via Large Language Models" addresses the issue of unreliable code generated by AI coding engines due to ambiguous natural language requirements. The authors introduce an approach to discover programmer intent by achieving consistency between the program, its formal specification, and tests through a novel repair engine called **program-proof co-evolution**. This involves generating code and its formal specification from the same natural language intent, verifying their alignment, and repairing them iteratively until consistency is achieved. The consistent, formal intent is then translated back into natural language for developer inspection. The paper introduces ProofRover, an implementation of the program-proof co-evolution algorithm, and demonstrates how disambiguating intent increases the percentage of verifiable auto-generated programs. The approach incorporates unit tests to further refine the intent and filter out vacuous specifications. The core idea is to generate a declarative and an operational description of the intent from LLMs - the specification and the program, respectively. The common intent is then extracted from each artifact and used as the basis for a conformance repair campaign. The campaign repairs both the declarative and operational descriptions to ensure their consistency, as confirmed by formal verification.

---
## Description of result

The research introduces a novel approach for **intent discovery** in AI-generated code by using a **program-proof co-evolution** repair engine, which enhances the verifiability and reliability of auto-generated code. The approach leverages formal verification techniques to align code, specifications, and tests, effectively reducing ambiguity and increasing the trustworthiness of AI-assisted software development. The experimental results demonstrate an increase in verifiable auto-generated programs using the **ProofRover** tool.

---

## How it compares to previous work

Previous automated program repair work focuses on synthesizing patches based on constraints derived from unit tests. Other studies explore using large language models (LLMs) to generate formal specifications. This work builds on these insights by developing a **co-evolution strategy** that enables the simultaneous repair of code, invariants, preconditions, and postconditions in an integrated manner. Unlike approaches that focus solely on code or proof repair, this method allows for the simultaneous evolution of code alongside proofs and specifications. Furthermore, the research uniquely uses tests as a hard constraint to represent the userâ€™s intent, guiding the entire evolution process.

---

## Main strategies used to obtain results

The main strategies employed to achieve the results are:

- **Generating code and specifications from natural language:** Using LLMs to create both the program and its formal specification from the same intent.
- **Formal verification:** Employing a verifier to check the alignment between the code and its specification.
- **Program-proof co-evolution:** Incrementally refining the understanding of user intent by repairing the code and its specification until they are consistent, using a tool called ProofRover.
- **Intent extraction:** Identifying common facts (hard intent) and disagreements (soft intent) between the code, specification, and tests to guide the repair process.
- **Using tests for disambiguation:** Incorporating unit tests to filter out vacuous specifications and further clarify developer intent.
- **Prioritising repair candidates:** Devising heuristics for choosing which facts to fix based on inconsistency with hard intent facts and strength of formulas.